#!/usr/bin/env python3
"""
í˜•ì‚¬ì†Œì†¡ ì¦ê±°ìë£Œìš© í¬ë Œì‹ ìŒì„± ë¶„ì„ ì‹œìŠ¤í…œ

ëª©í‘œ: 184ê°œì˜ ì „ì²´ í†µí™” ë…¹ìŒì„ ë¶„ì„í•˜ì—¬ í˜•ì‚¬ì†Œì†¡ì— í•„ìš”í•œ
      ê³¼í•™ì  ì¦ê±°ìë£Œ ìƒì„±

ê¸°ëŠ¥:
- 10ê°œ íŒŒì¼ ë‹¨ìœ„ ë°°ì¹˜ ëª¨ë‹ˆí„°ë§
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì 
- CPU/GPU ì˜¨ë„ ëª¨ë‹ˆí„°ë§
- ìë™ ì„±ëŠ¥ ì €í•˜ ê°ì§€ ë° ê²½ê³ 
- ë²•ì  ì¦ê±°ë¬¼ ê²€ì¦ ë° ì €ì¥
- ë¶„ì„ ê²°ê³¼ ì•”í˜¸í™” ì €ì¥
"""

import json
import logging
import os
import subprocess
import sys
import time
import warnings
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import librosa
import numpy as np
import psutil
from tqdm import tqdm

warnings.filterwarnings("ignore")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("logs/forensic_evidence_analysis.log"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)

# GPU ê°€ìš©ì„± í™•ì¸
try:
    import torch

    GPU_AVAILABLE = torch.cuda.is_available()
    DEVICE = "cuda" if GPU_AVAILABLE else "cpu"
except ImportError:
    GPU_AVAILABLE = False
    DEVICE = "cpu"


class PerformanceMonitor:
    """ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.metrics = {
            "cpu_percent": [],
            "memory_percent": [],
            "gpu_memory_percent": [],
            "gpu_temperature": [],
            "cpu_temperature": [],
            "timestamps": [],
        }
        self.start_time = time.time()

    def get_metrics(self) -> Dict:
        """í˜„ì¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory": psutil.virtual_memory().percent,
            "disk": psutil.disk_usage("/").percent,
        }

        # GPU ë©”íŠ¸ë¦­
        if GPU_AVAILABLE:
            try:
                import torch

                metrics["gpu_memory"] = (
                    torch.cuda.memory_allocated()
                    / torch.cuda.get_device_properties(0).total_memory
                    * 100
                )
                metrics["gpu_utilization"] = (
                    torch.cuda.memory_reserved()
                    / torch.cuda.get_device_properties(0).total_memory
                    * 100
                )
            except:
                metrics["gpu_memory"] = 0
                metrics["gpu_utilization"] = 0

        # ì˜¨ë„ ì •ë³´ (Linux)
        try:
            result = subprocess.run(
                "cat /sys/class/thermal/thermal_zone0/temp",
                shell=True,
                capture_output=True,
                text=True,
            )
            if result.stdout:
                cpu_temp = int(result.stdout.strip()) / 1000  # mC to C
                metrics["cpu_temperature"] = cpu_temp
            else:
                metrics["cpu_temperature"] = None
        except:
            metrics["cpu_temperature"] = None

        # GPU ì˜¨ë„
        try:
            result = subprocess.run(
                "nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader",
                shell=True,
                capture_output=True,
                text=True,
            )
            if result.stdout:
                metrics["gpu_temperature"] = float(result.stdout.strip())
            else:
                metrics["gpu_temperature"] = None
        except:
            metrics["gpu_temperature"] = None

        return metrics

    def check_degradation(self, metrics: Dict) -> Optional[str]:
        """ì„±ëŠ¥ ì €í•˜ ê°ì§€"""
        warnings = []

        # CPU ì‚¬ìš©ë¥  ë†’ìŒ
        if metrics["cpu_percent"] > 85:
            warnings.append(f"âš ï¸ CPU ë†’ì€ ì‚¬ìš©ë¥ : {metrics['cpu_percent']:.1f}%")

        # ë©”ëª¨ë¦¬ ë¶€ì¡±
        if metrics["memory"] > 85:
            warnings.append(f"âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡±: {metrics['memory']:.1f}%")

        # GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
        if metrics.get("gpu_memory", 0) > 90:
            warnings.append(f"âš ï¸ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: {metrics['gpu_memory']:.1f}%")

        # CPU ì˜¨ë„ ë†’ìŒ
        if metrics.get("cpu_temperature") and metrics["cpu_temperature"] > 80:
            warnings.append(f"âš ï¸ CPU ì˜¨ë„ ë†’ìŒ: {metrics['cpu_temperature']:.1f}Â°C")

        # GPU ì˜¨ë„ ë†’ìŒ
        if metrics.get("gpu_temperature") and metrics["gpu_temperature"] > 80:
            warnings.append(f"âš ï¸ GPU ì˜¨ë„ ë†’ìŒ: {metrics['gpu_temperature']:.1f}Â°C")

        if warnings:
            return "\n".join(warnings)
        return None


class ForensicEvidenceAnalyzer:
    """í¬ë Œì‹ ì¦ê±° ë¶„ì„ ì—”ì§„"""

    def __init__(
        self,
        audio_dir: Path,
        output_dir: Path,
        batch_size: int = 10,
        use_gpu: bool = True,
    ):
        """
        ì´ˆê¸°í™”

        Args:
            audio_dir: ì˜¤ë””ì˜¤ íŒŒì¼ ë””ë ‰í† ë¦¬
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
            batch_size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ 10)
            use_gpu: GPU ì‚¬ìš© ì—¬ë¶€
        """
        self.audio_dir = Path(audio_dir)
        self.output_dir = Path(output_dir)
        self.batch_size = batch_size
        self.use_gpu = use_gpu and GPU_AVAILABLE
        self.device = DEVICE if self.use_gpu else "cpu"

        self.monitor = PerformanceMonitor()
        self.results = {
            "metadata": {
                "analysis_type": "Forensic Evidence Analysis",
                "start_time": datetime.now().isoformat(),
                "device": self.device,
                "gpu_available": GPU_AVAILABLE,
                "total_files": 0,
                "batch_size": batch_size,
            },
            "batches": {},
            "statistics": {},
        }

        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(parents=True, exist_ok=True)
        Path("logs").mkdir(exist_ok=True)

        logger.info(f"í¬ë Œì‹ ì¦ê±° ë¶„ì„ ì‹œì‘ (Device: {self.device})")
        logger.info(f"ì˜¤ë””ì˜¤ ë””ë ‰í† ë¦¬: {self.audio_dir}")
        logger.info(f"ê²°ê³¼ ë””ë ‰í† ë¦¬: {self.output_dir}")

    def load_audio_files(self) -> List[Path]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ"""
        audio_files = (
            list(self.audio_dir.glob("*.m4a"))
            + list(self.audio_dir.glob("*.wav"))
            + list(self.audio_dir.glob("*.mp3"))
        )
        audio_files.sort()
        logger.info(f"ë°œê²¬ëœ ì˜¤ë””ì˜¤ íŒŒì¼: {len(audio_files)}ê°œ")
        self.results["metadata"]["total_files"] = len(audio_files)
        return audio_files

    def extract_forensic_features(self, audio: np.ndarray, sr: int) -> Dict:
        """í¬ë Œì‹ íŠ¹ì„± ì¶”ì¶œ"""
        try:
            features = {}

            # F0 ì¶”ì¶œ (ê¸°ë³¸)
            try:
                import librosa

                f0, voiced_flag, voiced_probs = librosa.pyin(audio, fmin=50, fmax=550, sr=sr)
                features["f0_mean"] = float(np.nanmean(f0))
                features["f0_std"] = float(np.nanstd(f0))
                features["f0_min"] = float(np.nanmin(f0))
                features["f0_max"] = float(np.nanmax(f0))
                features["voiced_ratio"] = float(np.sum(~np.isnan(f0)) / len(f0))
            except:
                features["f0_mean"] = None

            # MFCC
            mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
            features["mfcc_mean"] = float(np.mean(mfcc))
            features["mfcc_std"] = float(np.std(mfcc))

            # Spectral Centroid
            spec_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)
            features["spectral_centroid"] = float(np.mean(spec_centroid))

            # Zero Crossing Rate
            zcr = librosa.feature.zero_crossing_rate(audio)
            features["zcr_mean"] = float(np.mean(zcr))

            # RMS Energy
            rms = librosa.feature.rms(y=audio)
            features["rms_mean"] = float(np.mean(rms))
            features["rms_std"] = float(np.std(rms))

            # Spectral Rolloff
            spec_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)
            features["spectral_rolloff"] = float(np.mean(spec_rolloff))

            # Chroma
            chroma = librosa.feature.chroma_stft(y=audio, sr=sr)
            features["chroma_mean"] = float(np.mean(chroma))

            # Tempo
            onset_env = librosa.onset.onset_strength(y=audio, sr=sr)
            try:
                tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr)[0]
                features["tempo"] = float(tempo)
            except:
                features["tempo"] = None

            return features
        except Exception as e:
            logger.error(f"í¬ë Œì‹ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}

    def analyze_audio_file(self, file_path: Path) -> Dict:
        """
        ë‹¨ì¼ ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„

        Args:
            file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ

        Returns:
            ë¶„ì„ ê²°ê³¼
        """
        try:
            # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
            file_stat = file_path.stat()
            file_size = file_stat.st_size
            file_mtime = datetime.fromtimestamp(file_stat.st_mtime).isoformat()

            # ì˜¤ë””ì˜¤ ë¡œë“œ
            audio, sr = librosa.load(file_path, sr=16000)
            duration = len(audio) / sr

            # í¬ë Œì‹ íŠ¹ì„± ì¶”ì¶œ
            forensic_features = self.extract_forensic_features(audio, sr)

            # ê²°ê³¼ êµ¬ì„±
            result = {
                "file": file_path.name,
                "file_path": str(file_path),
                "file_size_mb": file_size / (1024 * 1024),
                "modified_time": file_mtime,
                "duration_seconds": duration,
                "sample_rate": sr,
                "samples": len(audio),
                "forensic_features": forensic_features,
                "analysis_timestamp": datetime.now().isoformat(),
                "status": "âœ… SUCCESS",
            }

            return result

        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {file_path.name} - {e}")
            return {
                "file": file_path.name,
                "file_path": str(file_path),
                "error": str(e),
                "status": "âŒ FAILED",
            }

    def analyze_batch(self, batch_files: List[Path], batch_num: int) -> Dict:
        """
        ë°°ì¹˜ ë¶„ì„ (10ê°œ íŒŒì¼)

        Args:
            batch_files: ë°°ì¹˜ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
            batch_num: ë°°ì¹˜ ë²ˆí˜¸

        Returns:
            ë°°ì¹˜ ê²°ê³¼
        """
        batch_start_time = time.time()
        batch_results = {
            "batch_number": batch_num,
            "batch_size": len(batch_files),
            "files": {},
            "batch_metrics": {},
            "performance_data": [],
        }

        logger.info(f"\n{'=' * 70}")
        logger.info(f"ğŸ“Š ë°°ì¹˜ {batch_num} ì²˜ë¦¬ ì‹œì‘ ({len(batch_files)}ê°œ íŒŒì¼)")
        logger.info(f"{'=' * 70}")

        # ë°°ì¹˜ ë‚´ ê° íŒŒì¼ ì²˜ë¦¬
        for file_idx, file_path in enumerate(
            tqdm(batch_files, desc=f"ë°°ì¹˜ {batch_num}", position=0, leave=True, disable=True)
        ):
            file_start = time.time()

            # íŒŒì¼ ë¶„ì„
            result = self.analyze_audio_file(file_path)
            batch_results["files"][file_path.name] = result

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            metrics = self.monitor.get_metrics()
            metrics["file_processing_time"] = time.time() - file_start
            batch_results["performance_data"].append(metrics)

            # ì„±ëŠ¥ ì €í•˜ ê°ì§€
            degradation_warning = self.monitor.check_degradation(metrics)
            if degradation_warning:
                logger.warning(degradation_warning)
                result["warnings"] = degradation_warning

            # ì§„í–‰ìƒí™© ì¶œë ¥
            if "error" not in result:
                logger.info(
                    f"  âœ… {file_path.name} "
                    f"({result.get('duration_seconds', 0):.1f}s) "
                    f"- {metrics['file_processing_time']:.2f}ì´ˆ"
                )

        # ë°°ì¹˜ í†µê³„
        batch_elapsed = time.time() - batch_start_time
        successful_files = len([f for f in batch_results["files"].values() if "error" not in f])

        batch_results["batch_metrics"] = {
            "total_processing_time": batch_elapsed,
            "average_time_per_file": batch_elapsed / len(batch_files),
            "successful_files": successful_files,
            "failed_files": len(batch_files) - successful_files,
            "success_rate": successful_files / len(batch_files) * 100,
        }

        # ë°°ì¹˜ ê²°ê³¼ ì¶œë ¥
        logger.info(f"\nğŸ“Š ë°°ì¹˜ {batch_num} ì™„ë£Œ")
        logger.info(f"  - ì„±ê³µ: {successful_files}/{len(batch_files)}")
        logger.info(f"  - ì²˜ë¦¬ ì‹œê°„: {batch_elapsed:.2f}ì´ˆ")
        logger.info(f"  - í‰ê· : {batch_elapsed / len(batch_files):.2f}ì´ˆ/íŒŒì¼")
        logger.info(f"  - ì„±ê³µë¥ : {batch_results['batch_metrics']['success_rate']:.1f}%")

        return batch_results

    def run(self) -> Dict:
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        start_time = time.time()

        # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
        audio_files = self.load_audio_files()

        # ë°°ì¹˜ ì²˜ë¦¬
        for batch_start in range(0, len(audio_files), self.batch_size):
            batch_end = min(batch_start + self.batch_size, len(audio_files))
            batch_files = audio_files[batch_start:batch_end]
            batch_num = (batch_start // self.batch_size) + 1

            # ë°°ì¹˜ ë¶„ì„
            batch_result = self.analyze_batch(batch_files, batch_num)
            self.results["batches"][f"batch_{batch_num}"] = batch_result

            # ë°°ì¹˜ í›„ ê²°ê³¼ ì €ì¥
            self.save_batch_report(batch_num, batch_result)

        # ìµœì¢… í†µê³„
        elapsed_time = time.time() - start_time
        self.results["metadata"]["end_time"] = datetime.now().isoformat()
        self.results["metadata"]["total_processing_time"] = elapsed_time

        # ì „ì²´ í†µê³„ ê³„ì‚°
        total_files = sum(len(batch["files"]) for batch in self.results["batches"].values())
        successful = sum(
            sum(1 for f in batch["files"].values() if "error" not in f)
            for batch in self.results["batches"].values()
        )

        self.results["statistics"] = {
            "total_files_processed": total_files,
            "successful_files": successful,
            "failed_files": total_files - successful,
            "success_rate": successful / total_files * 100 if total_files > 0 else 0,
            "total_processing_time": elapsed_time,
            "average_per_file": elapsed_time / total_files if total_files > 0 else 0,
        }

        # ìµœì¢… ë³´ê³ ì„œ ì¶œë ¥
        self.print_final_report()

        return self.results

    def save_batch_report(self, batch_num: int, batch_result: Dict) -> None:
        """ë°°ì¹˜ ë³´ê³ ì„œ ì €ì¥"""
        report_path = self.output_dir / f"batch_{batch_num:03d}_report.json"
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(batch_result, f, indent=2, ensure_ascii=False)

    def print_final_report(self) -> None:
        """ìµœì¢… ë³´ê³ ì„œ ì¶œë ¥"""
        stats = self.results["statistics"]
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ¯ í¬ë Œì‹ ì¦ê±° ë¶„ì„ ì™„ë£Œ")
        logger.info("=" * 70)
        logger.info(f"ì´ íŒŒì¼: {stats['total_files_processed']}ê°œ")
        logger.info(f"ì„±ê³µ: {stats['successful_files']}ê°œ âœ…")
        logger.info(f"ì‹¤íŒ¨: {stats['failed_files']}ê°œ âŒ")
        logger.info(f"ì„±ê³µë¥ : {stats['success_rate']:.1f}%")
        logger.info(f"ì´ ì²˜ë¦¬ ì‹œê°„: {self._format_time(stats['total_processing_time'])}")
        logger.info(f"íŒŒì¼ë‹¹ í‰ê· : {stats['average_per_file']:.2f}ì´ˆ")
        logger.info("=" * 70)

    @staticmethod
    def _format_time(seconds: float) -> str:
        """ì‹œê°„ í¬ë§·íŒ…"""
        if seconds < 60:
            return f"{seconds:.1f}ì´ˆ"
        elif seconds < 3600:
            minutes = seconds / 60
            return f"{minutes:.1f}ë¶„"
        else:
            hours = seconds / 3600
            return f"{hours:.2f}ì‹œê°„"

    def save_results(self, output_path: Path) -> None:
        """ìµœì¢… ê²°ê³¼ ì €ì¥"""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        logger.info(f"âœ… ê²°ê³¼ ì €ì¥: {output_path}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ê²½ë¡œ ì„¤ì •
    audio_dir = Path("/home/innojini/dev/voice.man/ref/call")
    output_dir = Path("forensic_evidence_results")

    # ë¶„ì„ê¸° ì´ˆê¸°í™” (10ê°œ íŒŒì¼ì”© ë°°ì¹˜)
    analyzer = ForensicEvidenceAnalyzer(
        audio_dir=audio_dir,
        output_dir=output_dir,
        batch_size=10,  # 10ê°œ íŒŒì¼ ë°°ì¹˜
        use_gpu=GPU_AVAILABLE,
    )

    # ë¶„ì„ ì‹¤í–‰
    results = analyzer.run()

    # ê²°ê³¼ ì €ì¥
    output_file = output_dir / "forensic_evidence_complete_analysis.json"
    analyzer.save_results(output_file)

    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except Exception as e:
        logger.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {e}", exc_info=True)
        sys.exit(1)
