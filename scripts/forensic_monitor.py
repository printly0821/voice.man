#!/usr/bin/env python3
"""
í¬ë Œì‹ íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸

ì˜¤ë””ì˜¤ íŒŒì¼ì„ í¬ë Œì‹ íŒŒì´í”„ë¼ì¸ì— í†µê³¼ì‹œí‚¤ê³  10ê°œ ë‹¨ìœ„ë¡œ ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
STT ì •í™•ë„(ì‹ ë¢°ë„ ì ìˆ˜, WER/CER)ì™€ ì „ì‚¬ í†µê³„ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python scripts/forensic_monitor.py --input-dir ref/call
"""

# ============================================================================
# PyTorch 2.6+ í˜¸í™˜ì„± íŒ¨ì¹˜
# ============================================================================
import torch

_original_torch_load = torch.load


def _patched_torch_load(*args, weights_only=None, **kwargs):
    """í˜¸í™˜ì„±ì„ ìœ„í•œ torch.load íŒ¨ì¹˜"""
    if weights_only is None:
        weights_only = False
    return _original_torch_load(*args, weights_only=weights_only, **kwargs)


torch.load = _patched_torch_load
# ============================================================================

import argparse
import asyncio
import gc
import json
import logging
import sys
import threading
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

# src ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from dotenv import load_dotenv

load_dotenv()

from voice_man.services.whisperx_service import WhisperXService
from voice_man.services.forensic.audio_feature_service import AudioFeatureService
from voice_man.services.forensic.stress_analysis_service import StressAnalysisService
from voice_man.services.forensic.ser_service import SERService
from voice_man.services.forensic.crime_language_service import CrimeLanguageAnalysisService
from voice_man.services.forensic.cross_validation_service import CrossValidationService
from voice_man.services.forensic.forensic_scoring_service import ForensicScoringService
from voice_man.services.stt_accuracy_service import (
    STTAccuracyService,
    STTAccuracyResult,
)

try:
    from tabulate import tabulate

    HAS_TABULATE = True
except ImportError:
    HAS_TABULATE = False

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class SharedModelPool:
    """GPU ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•œ ìŠ¤ë ˆë“œ ì•ˆì „í•œ ê³µìœ  ëª¨ë¸ í’€"""

    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if not self._initialized:
            self._whisper_service = None
            self._forensic_services = None
            self._stt_accuracy_service = None
            self._service_lock = threading.Lock()
            self._whisper_lock = threading.Lock()
            self._forensic_lock = threading.Lock()
            self._initialized = True

    def get_whisper_service(
        self, model_size: str = "large-v3", device: str = "cuda", language: str = "ko"
    ) -> WhisperXService:
        """ê³µìœ  WhisperX ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
        with self._whisper_lock:
            if self._whisper_service is None:
                logger.info(f"WhisperX ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘: {model_size}")
                self._whisper_service = WhisperXService(
                    model_size=model_size,
                    device=device,
                    language=language,
                    compute_type="float16",
                )
                logger.info("WhisperX ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            return self._whisper_service

    def get_forensic_services(self) -> Dict[str, Any]:
        """ê³µìœ  í¬ë Œì‹ ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
        with self._forensic_lock:
            if self._forensic_services is None:
                logger.info("í¬ë Œì‹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘")

                audio_feature_service = AudioFeatureService()
                stress_analysis_service = StressAnalysisService()
                ser_service = SERService()
                crime_language_service = CrimeLanguageAnalysisService()
                cross_validation_service = CrossValidationService(
                    crime_language_service=crime_language_service,
                    ser_service=ser_service,
                )
                forensic_scoring_service = ForensicScoringService(
                    audio_feature_service=audio_feature_service,
                    stress_analysis_service=stress_analysis_service,
                    crime_language_service=crime_language_service,
                    ser_service=ser_service,
                    cross_validation_service=cross_validation_service,
                )

                self._forensic_services = {
                    "audio_feature": audio_feature_service,
                    "stress": stress_analysis_service,
                    "ser": ser_service,
                    "crime": crime_language_service,
                    "cross_validation": cross_validation_service,
                    "scoring": forensic_scoring_service,
                }
                logger.info("í¬ë Œì‹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            return self._forensic_services

    def get_stt_accuracy_service(self) -> STTAccuracyService:
        """STT ì •í™•ë„ ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
        with self._forensic_lock:
            if self._stt_accuracy_service is None:
                self._stt_accuracy_service = STTAccuracyService()
            return self._stt_accuracy_service

    def cleanup_all(self):
        """ëª¨ë“  ì„œë¹„ìŠ¤ ì •ë¦¬"""
        logger.info("ëª¨ë“  ì„œë¹„ìŠ¤ ì •ë¦¬ ì¤‘...")
        if self._whisper_service is not None:
            try:
                if hasattr(self._whisper_service, "unload"):
                    self._whisper_service.unload()
                del self._whisper_service
                self._whisper_service = None
            except Exception as e:
                logger.warning(f"Whisper ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        if self._forensic_services is not None:
            for name, service in self._forensic_services.items():
                try:
                    if hasattr(service, "unload"):
                        service.unload()
                    del service
                except Exception as e:
                    logger.warning(f"{name} ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            self._forensic_services = None

        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        logger.info("ëª¨ë“  ì„œë¹„ìŠ¤ ì •ë¦¬ ì™„ë£Œ")


async def process_single_file(
    audio_path: Path,
    model_pool: SharedModelPool,
    model_size: str,
) -> Optional[Dict[str, Any]]:
    """
    ë‹¨ì¼ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í¬ë Œì‹ ë¶„ì„ìœ¼ë¡œ ì²˜ë¦¬

    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (Path ê°ì²´)
        model_pool: ê³µìœ  ëª¨ë¸ í’€
        model_size: Whisper ëª¨ë¸ í¬ê¸°

    Returns:
        ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ì‹¤íŒ¨ ì‹œ None
    """
    audio_name = audio_path.name
    audio_path_str = str(audio_path.resolve())  # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜

    try:
        logger.info(f"ì²˜ë¦¬ ì¤‘: {audio_name}")

        # ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        whisper_service = model_pool.get_whisper_service(model_size=model_size)
        forensic_services = model_pool.get_forensic_services()
        stt_accuracy_service = model_pool.get_stt_accuracy_service()

        # ì „ì‚¬ ì‹¤í–‰
        logger.info(f"[{audio_name}] ì „ì‚¬ ê³„ì‚° ì¤‘...")
        transcript_result = await whisper_service.process_audio(audio_path_str)

        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        logger.info(f"[{audio_name}] ì „ì‚¬ ì™„ë£Œ")

        # STT ì •í™•ë„ ë¶„ì„
        logger.info(f"[{audio_name}] STT ì •í™•ë„ ë¶„ì„ ì¤‘...")
        stt_accuracy = stt_accuracy_service.analyze_from_pipeline_result(
            file_path=str(audio_path),
            pipeline_result=transcript_result,
            reference_text=None,  # ì°¸ì¡° í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì—¬ê¸°ì— ì „ë‹¬
        )

        # í¬ë Œì‹ ë¶„ì„ ì‹¤í–‰
        logger.info(f"[{audio_name}] í¬ë Œì‹ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        forensic_score = await forensic_services["scoring"].analyze(
            audio_path=str(audio_path),
            transcript=transcript_result.text,
        )

        # ì¹´í…Œê³ ë¦¬ ì ìˆ˜ ì¶”ì¶œ
        category_scores = {cs.category: cs for cs in forensic_score.category_scores}

        # ê²°ê³¼ ì¤€ë¹„ (STT ì •í™•ë„ í¬í•¨)
        result = {
            "file_name": audio_name,
            "file_path": str(audio_path),
            "duration_seconds": forensic_score.audio_duration_seconds,
            "transcript_text": transcript_result.text,
            "num_segments": len(transcript_result.segments),
            "num_speakers": len(transcript_result.speakers),
            # í¬ë Œì‹ ì ìˆ˜
            "overall_risk_score": forensic_score.overall_risk_score,
            "overall_risk_level": forensic_score.overall_risk_level,
            "confidence_level": getattr(forensic_score, "confidence_level", "N/A"),
            "gaslighting_score": category_scores.get(
                "gaslighting", type("obj", (object,), {"score": 0, "intensity": "N/A"})
            ).score,
            "gaslighting_intensity": getattr(
                category_scores.get("gaslighting"), "intensity", "N/A"
            ),
            "threat_score": category_scores.get(
                "threat", type("obj", (object,), {"score": 0, "intensity": "N/A"})
            ).score,
            "threat_intensity": getattr(category_scores.get("threat"), "intensity", "N/A"),
            "coercion_score": category_scores.get(
                "coercion", type("obj", (object,), {"score": 0, "intensity": "N/A"})
            ).score,
            "coercion_intensity": getattr(category_scores.get("coercion"), "intensity", "N/A"),
            "deception_score": category_scores.get(
                "deception", type("obj", (object,), {"score": 0, "intensity": "N/A"})
            ).score,
            "deception_intensity": getattr(category_scores.get("deception"), "intensity", "N/A"),
            "emotional_score": category_scores.get(
                "emotional_manipulation", type("obj", (object,), {"score": 0, "intensity": "N/A"})
            ).score,
            "emotional_intensity": getattr(
                category_scores.get("emotional_manipulation"), "intensity", "N/A"
            ),
            "voice_text_consistency": getattr(forensic_score, "voice_text_consistency", "N/A"),
            "cross_validation_consistency": getattr(
                forensic_score, "cross_validation_consistency", "N/A"
            ),
            "summary": forensic_score.summary,
            "recommendations": forensic_score.recommendations,
            "flags": forensic_score.flags,
            "processing_time": getattr(forensic_score, "processing_time_seconds", 0),
            # STT ì •í™•ë„ ë©”íŠ¸ë¦­
            "stt_confidence_avg": stt_accuracy.confidence.avg_word_confidence,
            "stt_confidence_min": stt_accuracy.confidence.min_word_confidence,
            "stt_confidence_max": stt_accuracy.confidence.max_word_confidence,
            "stt_confidence_grade": stt_accuracy.confidence.overall_confidence_grade,
            "stt_low_conf_words": stt_accuracy.confidence.low_confidence_words,
            "stt_low_conf_ratio": stt_accuracy.confidence.low_confidence_ratio,
            "stt_total_words": stt_accuracy.stats.total_words,
            "stt_unique_words": stt_accuracy.stats.unique_words,
            "stt_wer": stt_accuracy.errors.wer if stt_accuracy.errors else None,
            "stt_cer": stt_accuracy.errors.cer if stt_accuracy.errors else None,
            "stt_accuracy_grade": stt_accuracy.errors.accuracy_grade
            if stt_accuracy.errors
            else None,
            "stt_words_per_minute": stt_accuracy.stats.words_per_minute,
            "stt_korean_ratio": stt_accuracy.stats.korean_ratio,
            "stt_has_reference": stt_accuracy.has_reference,
            # í™”ìë³„ ì¸ì‹ ì •í™•ë„
            "stt_speaker_count": stt_accuracy.speaker_accuracy.speaker_count,
            "stt_speaker_words": stt_accuracy.speaker_accuracy.speaker_words,
            "stt_speaker_duration": stt_accuracy.speaker_accuracy.speaker_duration,
            "stt_speaker_confidence": stt_accuracy.speaker_accuracy.speaker_confidence,
            "stt_speaker_switches": stt_accuracy.speaker_accuracy.speaker_switches,
            "stt_speaker_switch_accuracy": stt_accuracy.speaker_accuracy.speaker_switch_accuracy,
            "stt_speaker_uniformity": stt_accuracy.speaker_accuracy.speaker_uniformity,
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì •í™•ë„
            "stt_avg_word_duration": stt_accuracy.timestamp_accuracy.avg_word_duration,
            "stt_min_word_duration": stt_accuracy.timestamp_accuracy.min_word_duration,
            "stt_max_word_duration": stt_accuracy.timestamp_accuracy.max_word_duration,
            "stt_avg_timestamp_gap": stt_accuracy.timestamp_accuracy.avg_timestamp_gap,
            "stt_max_timestamp_gap": stt_accuracy.timestamp_accuracy.max_timestamp_gap,
            "stt_timestamps_within_100ms": stt_accuracy.timestamp_accuracy.timestamps_within_100ms,
            "stt_timestamps_within_200ms": stt_accuracy.timestamp_accuracy.timestamps_within_200ms,
            "stt_timestamp_precision_ratio": stt_accuracy.timestamp_accuracy.timestamp_precision_ratio,
            # ë¬¸ì¥ ë‹¨ìœ„ ë¶„ì„
            "stt_total_sentences": stt_accuracy.sentence_metrics.total_sentences,
            "stt_avg_sentence_length": stt_accuracy.sentence_metrics.avg_sentence_length,
            "stt_avg_words_per_sentence": stt_accuracy.sentence_metrics.avg_words_per_sentence,
            "stt_complete_sentences": stt_accuracy.sentence_metrics.complete_sentences,
            "stt_sentence_completion_ratio": stt_accuracy.sentence_metrics.sentence_completion_ratio,
            "stt_punctuation_accuracy": stt_accuracy.sentence_metrics.punctuation_accuracy,
            "stt_missing_punctuation": stt_accuracy.sentence_metrics.missing_punctuation,
            # ìŒì„±-í…ìŠ¤íŠ¸ ì¼ì¹˜ë„
            "stt_voice_text_correlation": stt_accuracy.voice_text_consistency.voice_text_correlation,
            "stt_acoustic_feature_match": stt_accuracy.voice_text_consistency.acoustic_feature_match,
            "stt_rhythm_consistency": stt_accuracy.voice_text_consistency.rhythm_consistency,
            "stt_pause_distribution_match": stt_accuracy.voice_text_consistency.pause_distribution_match,
            "stt_overall_consistency_score": stt_accuracy.voice_text_consistency.overall_consistency_score,
            "stt_consistency_grade": stt_accuracy.voice_text_consistency.consistency_grade,
        }

        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        logger.info(
            f"[{audio_name}] ë¶„ì„ ì™„ë£Œ (ìœ„í—˜ë„: {result['overall_risk_score']:.1f}/100, ì‹ ë¢°ë„: {result['stt_confidence_grade']}ë“±ê¸‰)"
        )
        return result

    except Exception as e:
        logger.error(f"[{audio_name}] ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback

        logger.error(traceback.format_exc())
        return None


def display_results_table(results: List[Dict[str, Any]], title: str = "í¬ë Œì‹ ë¶„ì„ ê²°ê³¼"):
    """
    ê²°ê³¼ë¥¼ ê¹”ë”í•œ CLI í…Œì´ë¸”ë¡œ í‘œì‹œ

    Args:
        results: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        title: í…Œì´ë¸” ì œëª©
    """
    if not results:
        print("\n" + "=" * 150)
        print(f"{title}")
        print("=" * 150)
        print("í‘œì‹œí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("=" * 150)
        return

    print("\n" + "=" * 180)
    print(f"{title} ({len(results)}ê°œ íŒŒì¼)")
    print("=" * 180)

    # í…Œì´ë¸” í—¤ë” (í•œêµ­ì–´)
    headers = [
        "íŒŒì¼ëª…",
        "ê¸¸ì´",
        "í™”ì",
        "ìœ„í—˜ë„",
        "ë“±ê¸‰",
        "ì‹ ë¢°ë„",
        "ë‹¨ì–´ìˆ˜",
        "WPM",
        "ê°€ìŠ¤ë¼ì´íŒ…",
        "í˜‘ë°•",
        "ê°•ìš”",
        "ì‚¬ê¸°",
        "ê°ì •ì¡°ì‘",
        "ì²˜ë¦¬ì‹œê°„(s)",
    ]

    rows = []
    for r in results:
        # íŒŒì¼ëª… ì˜ë¼ì„œ í‘œì‹œ
        filename = r["file_name"]
        if len(filename) > 25:
            filename = filename[:22] + "..."
        elif len(filename) < 25:
            filename = filename.ljust(25)

        rows.append(
            [
                filename,
                f"{r['duration_seconds']:.1f}s",
                str(r["num_speakers"]),
                f"{r['overall_risk_score']:.1f}",
                r["overall_risk_level"],
                f"{r['stt_confidence_avg']:.2f}({r['stt_confidence_grade']})",
                str(r["stt_total_words"]),
                f"{r['stt_words_per_minute']:.0f}",
                f"{r['gaslighting_score']:.1f}",
                f"{r['threat_score']:.1f}",
                f"{r['coercion_score']:.1f}",
                f"{r['deception_score']:.1f}",
                f"{r['emotional_score']:.1f}",
                f"{r['processing_time']:.1f}",
            ]
        )

    # í…Œì´ë¸” ì¶œë ¥
    if HAS_TABULATE:
        print(
            tabulate(rows, headers=headers, tablefmt="grid", stralign="center", numalign="center")
        )
    else:
        # ë‹¨ìˆœ í…Œì´ë¸” í˜•ì‹ ëŒ€ì²´
        print("-" * 180)
        header_row = f"{headers[0]:<25} " + " ".join(f"{h:>12}" for h in headers[1:])
        print(header_row)
        print("-" * 180)
        for row in rows:
            row_str = f"{row[0]:<25} " + " ".join(f"{r:>12}" for r in row[1:])
            print(row_str)

    print("=" * 180)

    # í†µê³„ ê³„ì‚° ë° í‘œì‹œ
    if len(results) > 0:
        avg_risk = sum(r["overall_risk_score"] for r in results) / len(results)
        high_risk_count = sum(1 for r in results if r["overall_risk_score"] >= 60)
        critical_count = sum(1 for r in results if r["overall_risk_score"] >= 80)

        # STT ì‹ ë¢°ë„ í†µê³„
        avg_confidence = sum(r["stt_confidence_avg"] for r in results) / len(results)
        grade_dist = {}
        for r in results:
            g = r["stt_confidence_grade"]
            grade_dist[g] = grade_dist.get(g, 0) + 1

        print("\nğŸ“Š í†µê³„:")
        print(f"  í‰ê·  ìœ„í—˜ë„ ì ìˆ˜: {avg_risk:.1f}/100")
        print(f"  ê³ ìœ„í—˜ íŒŒì¼ (â‰¥60): {high_risk_count}/{len(results)}")
        print(f"  ì‹¬ê° íŒŒì¼ (â‰¥80): {critical_count}/{len(results)}")
        print(f"  í‰ê·  STT ì‹ ë¢°ë„: {avg_confidence:.3f}")
        print(f"  ì‹ ë¢°ë„ ë“±ê¸‰ ë¶„í¬: {grade_dist}")

        # WER/CER í†µê³„ (ì°¸ì¡°ê°€ ìˆëŠ” íŒŒì¼ë§Œ)
        results_with_ref = [r for r in results if r["stt_has_reference"]]
        if results_with_ref:
            avg_wer = sum(r["stt_wer"] for r in results_with_ref if r["stt_wer"]) / len(
                results_with_ref
            )
            avg_cer = sum(r["stt_cer"] for r in results_with_ref if r["stt_cer"]) / len(
                results_with_ref
            )
            print(f"\nğŸ“ ì˜¤ë¥˜ìœ¨ (ì°¸ì¡° ìˆëŠ” {len(results_with_ref)}ê°œ íŒŒì¼):")
            print(f"  í‰ê·  WER: {avg_wer:.3f}")
            print(f"  í‰ê·  CER: {avg_cer:.3f}")

        # ì¹´í…Œê³ ë¦¬ë³„ í‰ê· 
        print("\nğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ í‰ê· :")
        print(f"  ê°€ìŠ¤ë¼ì´íŒ…: {sum(r['gaslighting_score'] for r in results) / len(results):.1f}")
        print(f"  í˜‘ë°•: {sum(r['threat_score'] for r in results) / len(results):.1f}")
        print(f"  ê°•ìš”: {sum(r['coercion_score'] for r in results) / len(results):.1f}")
        print(f"  ì‚¬ê¸°: {sum(r['deception_score'] for r in results) / len(results):.1f}")
        print(f"  ê°ì • ì¡°ì‘: {sum(r['emotional_score'] for r in results) / len(results):.1f}")

    print("=" * 180 + "\n")


def display_stt_accuracy_table(results: List[Dict[str, Any]]):
    """
    STT ì •í™•ë„ ì „ìš© í…Œì´ë¸” í‘œì‹œ

    Args:
        results: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    if not results:
        return

    print("\n" + "=" * 140)
    print("ğŸ¯ STT ì •í™•ë„ ìƒì„¸")
    print("=" * 140)

    headers = [
        "íŒŒì¼ëª…",
        "ì‹ ë¢°ë„",
        "ë“±ê¸‰",
        "ìµœì €/ìµœê³ ",
        "ì €ì‹ ë¢°ë‹¨ì–´",
        "ì´ë‹¨ì–´",
        "ê³ ìœ ë‹¨ì–´",
        "WPM",
        "í•œê¸€ë¹„ìœ¨",
        "WER",
        "CER",
    ]

    rows = []
    for r in results:
        filename = r["file_name"]
        if len(filename) > 20:
            filename = filename[:17] + "..."

        rows.append(
            [
                filename,
                f"{r['stt_confidence_avg']:.3f}",
                r["stt_confidence_grade"],
                f"{r['stt_confidence_min']:.2f}/{r['stt_confidence_max']:.2f}",
                f"{r['stt_low_conf_words']}({r['stt_low_conf_ratio']:.1%})",
                str(r["stt_total_words"]),
                str(r["stt_unique_words"]),
                f"{r['stt_words_per_minute']:.0f}",
                f"{r['stt_korean_ratio']:.1%}",
                f"{r['stt_wer']:.3f}" if r["stt_wer"] else "N/A",
                f"{r['stt_cer']:.3f}" if r["stt_cer"] else "N/A",
            ]
        )

    if HAS_TABULATE:
        print(
            tabulate(rows, headers=headers, tablefmt="grid", stralign="center", numalign="center")
        )
    else:
        print("-" * 140)
        header_row = f"{headers[0]:<20} " + " ".join(f"{h:>10}" for h in headers[1:])
        print(header_row)
        print("-" * 140)
        for row in rows:
            row_str = f"{row[0]:<20} " + " ".join(f"{r:>10}" for r in row[1:])
            print(row_str)

    print("=" * 140 + "\n")


def display_speaker_accuracy_table(results: List[Dict[str, Any]]):
    """
    í™”ìë³„ ì¸ì‹ ì •í™•ë„ í…Œì´ë¸” í‘œì‹œ

    Args:
        results: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    if not results:
        return

    print("\n" + "=" * 160)
    print("ğŸ¤ í™”ìë³„ ì¸ì‹ ì •í™•ë„ ìƒì„¸")
    print("=" * 160)

    headers = [
        "íŒŒì¼ëª…",
        "í™”ììˆ˜",
        "í™”ìë³„ ë‹¨ì–´",
        "í™”ìë³„ ë°œí™”ì‹œê°„(ì´ˆ)",
        "í™”ìë³„ ì‹ ë¢°ë„",
        "í™”ìì „í™˜",
        "ì „í™˜ì •í™•ë„",
        "í™”ìê· í˜•",
    ]

    rows = []
    for r in results:
        filename = r["file_name"]
        if len(filename) > 18:
            filename = filename[:15] + "..."

        # í™”ìë³„ ë‹¨ì–´/ì‹œê°„/ì‹ ë¢°ë„ í¬ë§·íŒ…
        speaker_words = str(r["stt_speaker_words"])
        if len(speaker_words) > 25:
            speaker_words = speaker_words[:22] + "..."

        speaker_duration = str(r["stt_speaker_duration"])
        if len(speaker_duration) > 20:
            speaker_duration = speaker_duration[:17] + "..."

        speaker_conf = str(r["stt_speaker_confidence"])
        if len(speaker_conf) > 18:
            speaker_conf = speaker_conf[:15] + "..."

        rows.append(
            [
                filename,
                str(r["stt_speaker_count"]),
                speaker_words,
                speaker_duration,
                speaker_conf,
                str(r["stt_speaker_switches"]),
                f"{r['stt_speaker_switch_accuracy']:.2%}",
                f"{r['stt_speaker_uniformity']:.2f}",
            ]
        )

    if HAS_TABULATE:
        print(
            tabulate(rows, headers=headers, tablefmt="grid", stralign="center", numalign="center")
        )
    else:
        print("-" * 160)
        header_row = f"{headers[0]:<18} " + " ".join(f"{h:>12}" for h in headers[1:])
        print(header_row)
        print("-" * 160)
        for row in rows:
            row_str = f"{row[0]:<18} " + " ".join(f"{r:>12}" for r in row[1:])
            print(row_str)

    print("=" * 160 + "\n")


def display_timestamp_accuracy_table(results: List[Dict[str, Any]]):
    """
    íƒ€ì„ìŠ¤íƒ¬í”„ ì •í™•ë„ í…Œì´ë¸” í‘œì‹œ

    Args:
        results: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    if not results:
        return

    print("\n" + "=" * 160)
    print("â±ï¸  íƒ€ì„ìŠ¤íƒ¬í”„ ì •í™•ë„ ìƒì„¸")
    print("=" * 160)

    headers = [
        "íŒŒì¼ëª…",
        "í‰ê· ë‹¨ì–´ê¸¸ì´(ms)",
        "ìµœì†Œ/ìµœëŒ€(ms)",
        "í‰ê· íƒ€ì„ê°­(ms)",
        "ìµœëŒ€ê°­(ms)",
        "100msì´ë‚´",
        "200msì´ë‚´",
        "ì •ë°€ë„ë¹„ìœ¨",
    ]

    rows = []
    for r in results:
        filename = r["file_name"]
        if len(filename) > 18:
            filename = filename[:15] + "..."

        rows.append(
            [
                filename,
                f"{r['stt_avg_word_duration'] * 1000:.0f}",
                f"{r['stt_min_word_duration'] * 1000:.0f}/{r['stt_max_word_duration'] * 1000:.0f}",
                f"{r['stt_avg_timestamp_gap'] * 1000:.1f}",
                f"{r['stt_max_timestamp_gap'] * 1000:.0f}",
                f"{r['stt_timestamps_within_100ms']}ê°œ",
                f"{r['stt_timestamps_within_200ms']}ê°œ",
                f"{r['stt_timestamp_precision_ratio']:.2%}",
            ]
        )

    if HAS_TABULATE:
        print(
            tabulate(rows, headers=headers, tablefmt="grid", stralign="center", numalign="center")
        )
    else:
        print("-" * 160)
        header_row = f"{headers[0]:<18} " + " ".join(f"{h:>12}" for h in headers[1:])
        print(header_row)
        print("-" * 160)
        for row in rows:
            row_str = f"{row[0]:<18} " + " ".join(f"{r:>12}" for r in row[1:])
            print(row_str)

    print("=" * 160 + "\n")


def display_sentence_metrics_table(results: List[Dict[str, Any]]):
    """
    ë¬¸ì¥ ë‹¨ìœ„ ë¶„ì„ í…Œì´ë¸” í‘œì‹œ

    Args:
        results: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    if not results:
        return

    print("\n" + "=" * 160)
    print("ğŸ“ ë¬¸ì¥ ë‹¨ìœ„ ë¶„ì„ ìƒì„¸")
    print("=" * 160)

    headers = [
        "íŒŒì¼ëª…",
        "ë¬¸ì¥ìˆ˜",
        "í‰ê· ë¬¸ì¥ê¸¸ì´",
        "ë¬¸ì¥ë‹¹ë‹¨ì–´",
        "ì™„ê²°ë¬¸ì¥",
        "ì™„ê²°ë¹„ìœ¨",
        "ë¬¸ì¥ë¶€í˜¸ì •í™•ë„",
        "ëˆ„ë½ë¶€í˜¸",
    ]

    rows = []
    for r in results:
        filename = r["file_name"]
        if len(filename) > 18:
            filename = filename[:15] + "..."

        rows.append(
            [
                filename,
                str(r["stt_total_sentences"]),
                f"{r['stt_avg_sentence_length']:.1f}ì",
                f"{r['stt_avg_words_per_sentence']:.1f}ê°œ",
                f"{r['stt_complete_sentences']}/{r['stt_total_sentences']}",
                f"{r['stt_sentence_completion_ratio']:.1%}",
                f"{r['stt_punctuation_accuracy']:.1%}",
                str(r["stt_missing_punctuation"]),
            ]
        )

    if HAS_TABULATE:
        print(
            tabulate(rows, headers=headers, tablefmt="grid", stralign="center", numalign="center")
        )
    else:
        print("-" * 160)
        header_row = f"{headers[0]:<18} " + " ".join(f"{h:>12}" for h in headers[1:])
        print(header_row)
        print("-" * 160)
        for row in rows:
            row_str = f"{row[0]:<18} " + " ".join(f"{r:>12}" for r in row[1:])
            print(row_str)

    print("=" * 160 + "\n")


def display_voice_text_consistency_table(results: List[Dict[str, Any]]):
    """
    ìŒì„±-í…ìŠ¤íŠ¸ ì¼ì¹˜ë„ í…Œì´ë¸” í‘œì‹œ

    Args:
        results: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    if not results:
        return

    print("\n" + "=" * 160)
    print("ğŸµ ìŒì„±-í…ìŠ¤íŠ¸ ì¼ì¹˜ë„ ìƒì„¸")
    print("=" * 160)

    headers = [
        "íŒŒì¼ëª…",
        "ìŒì„±-í…ìŠ¤íŠ¸ìƒê´€",
        "ìŒí–¥íŠ¹ì„±ì¼ì¹˜",
        "ë¦¬ë“¬ì¼ì¹˜ë„",
        "ì‰¼ë¶„í¬ì¼ì¹˜",
        "ì¢…í•©ì¼ì¹˜ì ìˆ˜",
        "ì¼ì¹˜ë“±ê¸‰",
    ]

    rows = []
    for r in results:
        filename = r["file_name"]
        if len(filename) > 18:
            filename = filename[:15] + "..."

        rows.append(
            [
                filename,
                f"{r['stt_voice_text_correlation']:.2f}",
                f"{r['stt_acoustic_feature_match']:.2f}",
                f"{r['stt_rhythm_consistency']:.2f}",
                f"{r['stt_pause_distribution_match']:.2f}",
                f"{r['stt_overall_consistency_score']:.2f}",
                r["stt_consistency_grade"],
            ]
        )

    if HAS_TABULATE:
        print(
            tabulate(rows, headers=headers, tablefmt="grid", stralign="center", numalign="center")
        )
    else:
        print("-" * 160)
        header_row = f"{headers[0]:<18} " + " ".join(f"{h:>12}" for h in headers[1:])
        print(header_row)
        print("-" * 160)
        for row in rows:
            row_str = f"{row[0]:<18} " + " ".join(f"{r:>12}" for r in row[1:])
            print(row_str)

    print("=" * 160 + "\n")


def display_detailed_report(result: Dict[str, Any]):
    """
    ë‹¨ì¼ íŒŒì¼ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ í‘œì‹œ

    Args:
        result: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print("\n" + "â–“" * 80)
    print(f"ìƒì„¸ ë³´ê³ ì„œ: {result['file_name']}")
    print("â–“" * 80)

    print("\nğŸ“ íŒŒì¼ ì •ë³´:")
    print(f"  ê²½ë¡œ: {result['file_path']}")
    print(f"  ê¸¸ì´: {result['duration_seconds']:.1f}ì´ˆ")
    print(f"  í™”ì: {result['num_speakers']}ëª…")
    print(f"  ì„¸ê·¸ë¨¼íŠ¸: {result['num_segments']}ê°œ")

    print("\nğŸ¯ ìœ„í—˜ë„ í‰ê°€:")
    print(f"  ì „ì²´ ìœ„í—˜ë„ ì ìˆ˜: {result['overall_risk_score']:.1f}/100")
    print(f"  ìœ„í—˜ë„ ë“±ê¸‰: {result['overall_risk_level']}")
    print(f"  ì‹ ë¢°ìˆ˜ì¤€: {result['confidence_level']}")

    print("\nğŸ¤ STT ì •í™•ë„:")
    print(f"  í‰ê·  ì‹ ë¢°ë„: {result['stt_confidence_avg']:.3f}")
    print(f"  ì‹ ë¢°ë„ ë“±ê¸‰: {result['stt_confidence_grade']}ë“±ê¸‰")
    print(f"  ì‹ ë¢°ë„ ë²”ìœ„: {result['stt_confidence_min']:.2f} ~ {result['stt_confidence_max']:.2f}")
    print(f"  ì €ì‹ ë¢°ë„ ë‹¨ì–´: {result['stt_low_conf_words']}ê°œ ({result['stt_low_conf_ratio']:.1%})")
    print(f"  ì´ ë‹¨ì–´ìˆ˜: {result['stt_total_words']}ê°œ (ê³ ìœ : {result['stt_unique_words']}ê°œ)")
    print(f"  ë§í•˜ê¸° ì†ë„: ë¶„ë‹¹ {result['stt_words_per_minute']:.0f}ë‹¨ì–´")
    print(f"  í•œê¸€ ë¹„ìœ¨: {result['stt_korean_ratio']:.1%}")

    if result["stt_has_reference"] and result["stt_wer"]:
        print(f"  ë‹¨ì–´ ì˜¤ë¥˜ìœ¨ (WER): {result['stt_wer']:.3f} ({result['stt_accuracy_grade']}ë“±ê¸‰)")
        print(f"  ë¬¸ì ì˜¤ë¥˜ìœ¨ (CER): {result['stt_cer']:.3f}")

    print("\nğŸ¤ í™”ìë³„ ì¸ì‹ ì •í™•ë„:")
    print(f"  í™”ì ìˆ˜: {result['stt_speaker_count']}ëª…")
    print(f"  í™”ìë³„ ë‹¨ì–´ ìˆ˜: {result['stt_speaker_words']}")
    print(f"  í™”ìë³„ ë°œí™” ì‹œê°„: {result['stt_speaker_duration']}")
    print(f"  í™”ìë³„ ì‹ ë¢°ë„: {result['stt_speaker_confidence']}")
    print(f"  í™”ì ì „í™˜ íšŸìˆ˜: {result['stt_speaker_switches']}íšŒ")
    print(f"  í™”ì ì „í™˜ ì •í™•ë„: {result['stt_speaker_switch_accuracy']:.2%}")
    print(f"  í™”ì ê· í˜•ë„: {result['stt_speaker_uniformity']:.2f}")

    print("\nâ±ï¸  íƒ€ì„ìŠ¤íƒ¬í”„ ì •í™•ë„:")
    print(f"  í‰ê·  ë‹¨ì–´ ê¸¸ì´: {result['stt_avg_word_duration'] * 1000:.0f}ms")
    print(
        f"  ë‹¨ì–´ ê¸¸ì´ ë²”ìœ„: {result['stt_min_word_duration'] * 1000:.0f}ms ~ {result['stt_max_word_duration'] * 1000:.0f}ms"
    )
    print(f"  í‰ê·  íƒ€ì„ìŠ¤íƒ¬í”„ ê°­: {result['stt_avg_timestamp_gap'] * 1000:.1f}ms")
    print(f"  ìµœëŒ€ íƒ€ì„ìŠ¤íƒ¬í”„ ê°­: {result['stt_max_timestamp_gap'] * 1000:.0f}ms")
    print(f"  100ms ì´ë‚´ íƒ€ì„ìŠ¤íƒ¬í”„: {result['stt_timestamps_within_100ms']}ê°œ")
    print(f"  200ms ì´ë‚´ íƒ€ì„ìŠ¤íƒ¬í”„: {result['stt_timestamps_within_200ms']}ê°œ")
    print(f"  íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë°€ë„ ë¹„ìœ¨: {result['stt_timestamp_precision_ratio']:.2%}")

    print("\nğŸ“ ë¬¸ì¥ ë‹¨ìœ„ ë¶„ì„:")
    print(f"  ì´ ë¬¸ì¥ ìˆ˜: {result['stt_total_sentences']}ê°œ")
    print(f"  í‰ê·  ë¬¸ì¥ ê¸¸ì´: {result['stt_avg_sentence_length']:.1f}ì")
    print(f"  ë¬¸ì¥ë‹¹ í‰ê·  ë‹¨ì–´: {result['stt_avg_words_per_sentence']:.1f}ê°œ")
    print(
        f"  ì™„ê²° ë¬¸ì¥: {result['stt_complete_sentences']}/{result['stt_total_sentences']} ({result['stt_sentence_completion_ratio']:.1%})"
    )
    print(f"  ë¬¸ì¥ ë¶€í˜¸ ì •í™•ë„: {result['stt_punctuation_accuracy']:.1%}")
    print(f"  ëˆ„ë½ëœ ë¬¸ì¥ ë¶€í˜¸: {result['stt_missing_punctuation']}ê°œ")

    print("\nğŸµ ìŒì„±-í…ìŠ¤íŠ¸ ì¼ì¹˜ë„:")
    print(f"  ìŒì„±-í…ìŠ¤íŠ¸ ìƒê´€ê³„ìˆ˜: {result['stt_voice_text_correlation']:.3f}")
    print(f"  ìŒí–¥ íŠ¹ì„± ì¼ì¹˜ë„: {result['stt_acoustic_feature_match']:.3f}")
    print(f"  ë¦¬ë“¬ ì¼ì¹˜ë„: {result['stt_rhythm_consistency']:.3f}")
    print(f"  ì‰¼ ë¶„í¬ ì¼ì¹˜ë„: {result['stt_pause_distribution_match']:.3f}")
    print(f"  ì¢…í•© ì¼ì¹˜ ì ìˆ˜: {result['stt_overall_consistency_score']:.3f}")
    print(f"  ì¼ì¹˜ ë“±ê¸‰: {result['stt_consistency_grade']}")

    print("\nğŸ“Š ì¹´í…Œê³ ë¦¬ ì ìˆ˜:")
    print(
        f"  ê°€ìŠ¤ë¼ì´íŒ…: {result['gaslighting_score']:.1f}/100 ({result['gaslighting_intensity']})"
    )
    print(f"  í˜‘ë°•: {result['threat_score']:.1f}/100 ({result['threat_intensity']})")
    print(f"  ê°•ìš”: {result['coercion_score']:.1f}/100 ({result['coercion_intensity']})")
    print(f"  ì‚¬ê¸°: {result['deception_score']:.1f}/100 ({result['deception_intensity']})")
    print(f"  ê°ì • ì¡°ì‘: {result['emotional_score']:.1f}/100 ({result['emotional_intensity']})")

    print("\nğŸ” êµì°¨ ê²€ì¦:")
    print(f"  ìŒì„±-í…ìŠ¤íŠ¸ ì¼ì¹˜ì„±: {result['voice_text_consistency']}")
    print(f"  êµì°¨ ê²€ì¦ ì¼ì¹˜ì„±: {result['cross_validation_consistency']}")

    print("\nğŸ“ ìš”ì•½:")
    for line in result["summary"].split("\n"):
        print(f"  {line}")

    if result["flags"]:
        print("\nâš ï¸  í”Œë˜ê·¸:")
        for flag in result["flags"]:
            print(f"  - {flag}")

    if result["recommendations"]:
        print("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        for rec in result["recommendations"]:
            print(f"  - {rec}")

    print("\n" + "â–“" * 80 + "\n")


async def process_batch_async(
    audio_files: List[Path],
    model_size: str,
    update_interval: int = 10,
) -> List[Dict[str, Any]]:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ê³  ì£¼ê¸°ì ìœ¼ë¡œ ê²°ê³¼ í‘œì‹œ

    Args:
        audio_files: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        model_size: Whisper ëª¨ë¸ í¬ê¸°
        update_interval: Nê°œ íŒŒì¼ë§ˆë‹¤ ê²°ê³¼ í‘œì‹œ

    Returns:
        ëª¨ë“  ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    model_pool = SharedModelPool()
    results = []

    start_time = datetime.now()
    total_count = len(audio_files)

    logger.info("=" * 60)
    logger.info("í¬ë Œì‹ íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°ë§")
    logger.info("=" * 60)
    logger.info(f"ì²˜ë¦¬í•  íŒŒì¼: {total_count}ê°œ")
    logger.info(f"ì—…ë°ì´íŠ¸ ì£¼ê¸°: {update_interval}ê°œ")
    logger.info(f"ëª¨ë¸: {model_size}")
    logger.info("=" * 60)

    for i, audio_path in enumerate(audio_files, 1):
        file_start = datetime.now()
        result = await process_single_file(audio_path, model_pool, model_size)

        if result:
            result["processing_time"] = (datetime.now() - file_start).total_seconds()
            results.append(result)
            logger.info(
                f"[{i}/{total_count}] ì™„ë£Œ: {result['file_name']} (ìœ„í—˜ë„: {result['overall_risk_score']:.1f}, ì‹ ë¢°ë„: {result['stt_confidence_grade']})"
            )
        else:
            logger.error(f"[{i}/{total_count}] ì‹¤íŒ¨: {audio_path.name}")

        # update_intervalë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰ì— ì§„í–‰ ì—…ë°ì´íŠ¸ í‘œì‹œ
        if i % update_interval == 0 or i == total_count:
            display_results_table(results, title=f"ì§„í–‰ ìƒí™© ({i}/{total_count}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ)")
            display_stt_accuracy_table(results)
            # í™•ì¥ëœ STT ì •ë°€ë„ ë©”íŠ¸ë¦­ í‘œì‹œ
            display_speaker_accuracy_table(results)
            display_timestamp_accuracy_table(results)
            display_sentence_metrics_table(results)
            display_voice_text_consistency_table(results)

    # ì •ë¦¬
    model_pool.cleanup_all()

    # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ í‘œì‹œ
    total_time = (datetime.now() - start_time).total_seconds()
    logger.info(f"ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.1f}ì´ˆ")

    return results


async def main_async(args):
    """ë©”ì¸ ë¹„ë™ê¸° ì§„ì…ì """
    # ì˜¤ë””ì˜¤ íŒŒì¼ ì¬ê·€ì ìœ¼ë¡œ ì°¾ê¸°
    audio_files = []
    for ext in ["*.m4a", "*.wav", "*.mp3", "*.flac"]:
        audio_files.extend(Path(args.input_dir).rglob(ext))

    # ì¼ê´€ëœ ì²˜ë¦¬ë¥¼ ìœ„í•´ íŒŒì¼ ì •ë ¬
    audio_files = sorted(audio_files)

    if args.limit:
        audio_files = audio_files[: args.limit]

    if not audio_files:
        print(f"\nâŒ {args.input_dir}ì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
        return 1

    # íŒŒì¼ ì²˜ë¦¬
    results = await process_batch_async(
        audio_files=audio_files,
        model_size=args.model,
        update_interval=args.update_interval,
    )

    # ìµœì¢… ìš”ì•½ í…Œì´ë¸”
    display_results_table(results, title="ìµœì¢… ê²°ê³¼ - í¬ë Œì‹ ë¶„ì„ ì™„ë£Œ")
    display_stt_accuracy_table(results)
    # í™•ì¥ëœ STT ì •ë°€ë„ ë©”íŠ¸ë¦­ ìµœì¢… ìš”ì•½
    display_speaker_accuracy_table(results)
    display_timestamp_accuracy_table(results)
    display_sentence_metrics_table(results)
    display_voice_text_consistency_table(results)

    # ìš”ì²­ ì‹œ ìƒì„¸ ë³´ê³ ì„œ í‘œì‹œ
    if args.verbose and results:
        for result in results:
            display_detailed_report(result)

    # JSONìœ¼ë¡œ ê²°ê³¼ ì €ì¥
    if args.output:
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {output_path}")

    return 0


def main():
    parser = argparse.ArgumentParser(
        description="í¬ë Œì‹ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ë¥¼ CLI í…Œì´ë¸”ë¡œ ëª¨ë‹ˆí„°ë§ (STT ì •í™•ë„ í¬í•¨)"
    )
    parser.add_argument(
        "--input-dir",
        default="ref/call",
        help="ì˜¤ë””ì˜¤ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: ref/call)",
    )
    parser.add_argument(
        "--output",
        "-o",
        help="ê²°ê³¼ ì¶œë ¥ JSON íŒŒì¼",
    )
    parser.add_argument(
        "--limit",
        type=int,
        help="ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜ ì œí•œ",
    )
    parser.add_argument(
        "--update-interval",
        type=int,
        default=10,
        help="Nê°œ íŒŒì¼ë§ˆë‹¤ ê²°ê³¼ í‘œì‹œ (ê¸°ë³¸ê°’: 10)",
    )
    parser.add_argument(
        "--model",
        default="large-v3",
        choices=[
            "tiny",
            "base",
            "small",
            "medium",
            "large-v1",
            "large-v2",
            "large-v3",
            "distil-large-v3",
        ],
        help="Whisper ëª¨ë¸ í¬ê¸° (ê¸°ë³¸ê°’: large-v3)",
    )
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="ê° íŒŒì¼ì— ëŒ€í•œ ìƒì„¸ ë³´ê³ ì„œ í‘œì‹œ",
    )

    args = parser.parse_args()

    if not HAS_TABULATE:
        print("\nâš ï¸  'tabulate' íŒ¨í‚¤ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” ë‚˜ì€ í…Œì´ë¸” í˜•ì‹ì„ ìœ„í•´ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("   pip install tabulate\n")

    return asyncio.run(main_async(args))


if __name__ == "__main__":
    sys.exit(main())
