#!/usr/bin/env python3
"""
í¬ë Œì‹ ì¦ê±° ë¶„ì„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

ê¸°ëŠ¥:
- 10ê°œ íŒŒì¼ ë°°ì¹˜ë³„ ì§„í–‰ ìƒí™© í‘œì‹œ
- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì‹¤ì‹œê°„ ì¶”ì 
- CPU/GPU ì˜¨ë„ ëª¨ë‹ˆí„°ë§
- ì„±ëŠ¥ ì €í•˜ ìë™ ê°ì§€
- ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
"""

import json
import os
import subprocess
import sys
import threading
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List

import psutil


class ForensicMonitoringDashboard:
    """í¬ë Œì‹ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ"""

    def __init__(self, log_file: Path = Path("logs/forensic_evidence_analysis.log")):
        """ì´ˆê¸°í™”"""
        self.log_file = log_file
        self.batch_stats = {}
        self.current_batch = 0
        self.total_batches = 0
        self.start_time = time.time()

    def get_system_metrics(self) -> Dict:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        metrics = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory_percent": psutil.virtual_memory().percent,
            "disk_percent": psutil.disk_usage("/").percent,
        }

        # GPU ë©”íŠ¸ë¦­
        try:
            result = subprocess.run(
                "nvidia-smi --query-gpu=memory.used,memory.total,temperature.gpu --format=csv,noheader,nounits",
                shell=True,
                capture_output=True,
                text=True,
                timeout=5,
            )
            if result.stdout:
                parts = result.stdout.strip().split(",")
                metrics["gpu_memory_used"] = float(parts[0])
                metrics["gpu_memory_total"] = float(parts[1])
                metrics["gpu_temp"] = float(parts[2])
                metrics["gpu_memory_percent"] = (
                    metrics["gpu_memory_used"] / metrics["gpu_memory_total"] * 100
                )
            else:
                metrics["gpu_available"] = False
        except Exception:
            metrics["gpu_available"] = False

        # CPU ì˜¨ë„
        try:
            result = subprocess.run(
                "cat /sys/class/thermal/thermal_zone0/temp",
                shell=True,
                capture_output=True,
                text=True,
                timeout=5,
            )
            if result.stdout:
                metrics["cpu_temp"] = int(result.stdout.strip()) / 1000
            else:
                metrics["cpu_temp"] = None
        except Exception:
            metrics["cpu_temp"] = None

        return metrics

    def print_header(self) -> None:
        """í—¤ë” ì¶œë ¥"""
        os.system("clear" if os.name == "posix" else "cls")
        print("\n" + "=" * 100)
        print("ğŸ” í¬ë Œì‹ ì¦ê±° ë¶„ì„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ".center(100))
        print("=" * 100)

    def print_batch_progress(self) -> None:
        """ë°°ì¹˜ ì§„í–‰ ìƒí™© ì¶œë ¥"""
        print("\nğŸ“Š ë°°ì¹˜ ì§„í–‰ ìƒí™©")
        print("-" * 100)

        # ë°°ì¹˜ë³„ í†µê³„
        if self.batch_stats:
            for batch_num, stats in sorted(self.batch_stats.items()):
                status = "âœ…" if stats["completed"] else "ğŸ”„"
                progress = (
                    f"{stats['processed']}/{stats['total']}"
                    if not stats["completed"]
                    else f"{stats['total']}/{stats['total']}"
                )

                print(
                    f"{status} ë°°ì¹˜ {batch_num:2d}: "
                    f"{progress:>5s} íŒŒì¼ | "
                    f"ì‹œê°„: {stats['elapsed']:.1f}ì´ˆ | "
                    f"í‰ê· : {stats['avg_per_file']:.2f}ì´ˆ/íŒŒì¼ | "
                    f"ì„±ê³µë¥ : {stats['success_rate']:.0f}%"
                )

    def print_system_status(self, metrics: Dict) -> None:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥"""
        print("\nğŸ’» ì‹œìŠ¤í…œ ìƒíƒœ")
        print("-" * 100)

        # CPU
        cpu_status = "âœ…" if metrics["cpu_percent"] < 80 else "âš ï¸"
        print(
            f"{cpu_status} CPU: {metrics['cpu_percent']:>5.1f}% | "
            f"ë©”ëª¨ë¦¬: {metrics['memory_percent']:>5.1f}% | "
            f"ë””ìŠ¤í¬: {metrics['disk_percent']:>5.1f}%"
        )

        # GPU
        if metrics.get("gpu_available", True):
            gpu_status = "âœ…" if metrics.get("gpu_memory_percent", 0) < 90 else "âš ï¸"
            gpu_temp_status = "âœ…" if metrics.get("gpu_temp", 0) < 80 else "âš ï¸"
            print(
                f"{gpu_status} GPU ë©”ëª¨ë¦¬: {metrics.get('gpu_memory_percent', 0):>5.1f}% | "
                f"{gpu_temp_status} GPU ì˜¨ë„: {metrics.get('gpu_temp', 0):>5.1f}Â°C"
            )

        # ì˜¨ë„
        if metrics.get("cpu_temp"):
            cpu_temp_status = "âœ…" if metrics["cpu_temp"] < 80 else "âš ï¸"
            print(f"{cpu_temp_status} CPU ì˜¨ë„: {metrics['cpu_temp']:>5.1f}Â°C")

    def print_performance_alerts(self, metrics: Dict) -> None:
        """ì„±ëŠ¥ ê²½ê³  ì¶œë ¥"""
        print("\nâš ï¸ ì„±ëŠ¥ ê²½ê³ ")
        print("-" * 100)

        alerts = []

        if metrics["cpu_percent"] > 85:
            alerts.append(f"ğŸ”´ CPU ë†’ì€ ì‚¬ìš©ë¥ : {metrics['cpu_percent']:.1f}%")

        if metrics["memory_percent"] > 85:
            alerts.append(f"ğŸ”´ ë©”ëª¨ë¦¬ ë¶€ì¡±: {metrics['memory_percent']:.1f}%")

        if metrics.get("gpu_memory_percent", 0) > 90:
            alerts.append(f"ğŸ”´ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: {metrics['gpu_memory_percent']:.1f}%")

        if metrics.get("cpu_temp") and metrics["cpu_temp"] > 80:
            alerts.append(f"ğŸŸ  CPU ì˜¨ë„ ë†’ìŒ: {metrics['cpu_temp']:.1f}Â°C")

        if metrics.get("gpu_temp") and metrics["gpu_temp"] > 80:
            alerts.append(f"ğŸŸ  GPU ì˜¨ë„ ë†’ìŒ: {metrics['gpu_temp']:.1f}Â°C")

        if alerts:
            for alert in alerts:
                print(f"  {alert}")
        else:
            print("  âœ… ëª¨ë“  ì‹œìŠ¤í…œ ì •ìƒ")

    def print_timeline(self) -> None:
        """íƒ€ì„ë¼ì¸ ì¶œë ¥"""
        elapsed = time.time() - self.start_time
        minutes = int(elapsed / 60)
        seconds = int(elapsed % 60)

        print("\nâ±ï¸ ì²˜ë¦¬ ì‹œê°„")
        print("-" * 100)
        print(f"ê²½ê³¼ ì‹œê°„: {minutes:02d}:{seconds:02d}")

        if self.batch_stats:
            total_batches = len(self.batch_stats)
            completed = sum(1 for b in self.batch_stats.values() if b["completed"])

            if completed > 0 and completed < total_batches:
                avg_batch_time = sum(b["elapsed"] for b in self.batch_stats.values()) / completed
                remaining_batches = total_batches - completed
                estimated_remaining = avg_batch_time * remaining_batches
                estimated_total = elapsed + estimated_remaining

                est_hours = int(estimated_remaining / 3600)
                est_minutes = int((estimated_remaining % 3600) / 60)
                est_seconds = int(estimated_remaining % 60)

                print(f"ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {est_hours}ì‹œê°„ {est_minutes}ë¶„ {est_seconds}ì´ˆ")
                print(
                    f"ì˜ˆìƒ ì´ ì‹œê°„: {int(estimated_total / 3600)}ì‹œê°„ "
                    f"{int((estimated_total % 3600) / 60)}ë¶„"
                )

    def print_recommendations(self, metrics: Dict) -> None:
        """ê¶Œì¥ ì‚¬í•­ ì¶œë ¥"""
        print("\nğŸ’¡ ê¶Œì¥ ì‚¬í•­")
        print("-" * 100)

        recommendations = []

        if metrics["cpu_percent"] > 75:
            recommendations.append("â€¢ CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì‘ì—… ì¢…ë£Œë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")

        if metrics["memory_percent"] > 75:
            recommendations.append("â€¢ ë©”ëª¨ë¦¬ ë¶€ì¡± ìƒíƒœì…ë‹ˆë‹¤. ë°°ì¹˜ í¬ê¸° ì¶•ì†Œë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")

        if metrics.get("gpu_memory_percent", 0) > 75:
            recommendations.append("â€¢ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ìƒíƒœì…ë‹ˆë‹¤. ë°°ì¹˜ í¬ê¸° ì¶•ì†Œë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")

        if metrics.get("cpu_temp") and metrics["cpu_temp"] > 70:
            recommendations.append("â€¢ CPU ì˜¨ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ëƒ‰ê°ì„ ê°•í™”í•˜ì„¸ìš”.")

        if metrics.get("gpu_temp") and metrics["gpu_temp"] > 70:
            recommendations.append("â€¢ GPU ì˜¨ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ëƒ‰ê°ì„ ê°•í™”í•˜ì„¸ìš”.")

        if recommendations:
            for rec in recommendations:
                print(f"  {rec}")
        else:
            print("  âœ… ì‹œìŠ¤í…œì´ ìµœì  ìƒíƒœì…ë‹ˆë‹¤.")

    def display_dashboard(self) -> None:
        """ëŒ€ì‹œë³´ë“œ í‘œì‹œ"""
        while True:
            try:
                self.print_header()

                metrics = self.get_system_metrics()

                self.print_batch_progress()
                self.print_system_status(metrics)
                self.print_performance_alerts(metrics)
                self.print_timeline()
                self.print_recommendations(metrics)

                print("\n" + "=" * 100)
                print(
                    f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {metrics['timestamp']} | "
                    "ì…ë ¥: Q(ì¢…ë£Œ), P(ì¼ì‹œì •ì§€), R(ì¬ê°œ)".center(100)
                )
                print("=" * 100 + "\n")

                time.sleep(5)  # 5ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸

            except KeyboardInterrupt:
                print("\nëŒ€ì‹œë³´ë“œ ì¢…ë£Œ")
                break
            except Exception as e:
                print(f"ëŒ€ì‹œë³´ë“œ ì˜¤ë¥˜: {e}")
                time.sleep(5)

    def update_batch_stats(self, batch_num: int, stats: Dict) -> None:
        """ë°°ì¹˜ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.batch_stats[batch_num] = stats


def start_monitoring_dashboard() -> None:
    """ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì‹œì‘"""
    dashboard = ForensicMonitoringDashboard()
    dashboard.display_dashboard()


if __name__ == "__main__":
    start_monitoring_dashboard()
